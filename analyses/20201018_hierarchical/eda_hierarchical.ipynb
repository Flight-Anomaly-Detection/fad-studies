{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 20201018 - Exploratory Data Analysis\n",
    "\n",
    "Topic: Hierarchical clustering\n",
    "\n",
    "This report describes a preliminary analysis of hierarchical clustering. The Python library scipy was used for the agglomerative clustering process and for creating the dendrogram. Later the silhouette was calculated in order to assess the clustering process quality."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports and functions\n",
    "\n",
    "The first step is to import the useful modules and define functions to be used throughout the file. Each of the functions used contains docstrings with specific details."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(flights_folder, n_observations):\n",
    "    \"\"\"\n",
    "    Reads flight data and returns a dataframe containing flight id and the\n",
    "    flight vector x.\n",
    "\n",
    "    x = [x_1_t1,x_1_t2,...,x_1_tn,...,x_i_tj,...,x_m_t1,x_m_t2,...,x_m_tn]\n",
    "\n",
    "    where:\n",
    "        x_i_tj  <- value of the i-th flight parameter at time tj.\n",
    "        m       <- total number of parameters\n",
    "        n       <- number of samples for every parameter\n",
    "\n",
    "    Similar to Cluster AD Flight, defined by Li and Hansman (2013).\n",
    "\n",
    "    References:\n",
    "    \n",
    "    Li, Lishuai, and R John Hansman. 2013. “Anomaly Detection in Airline \n",
    "    Routine Operations Using Flight Data Recorder Data.” PhD thesis, \n",
    "    Cambridge, MA: Massachusetts Institute of Technology.\n",
    "    \"\"\"\n",
    "    flights_list = os.listdir(flights_folder)\n",
    "\n",
    "    flight_vector = []\n",
    "    for flight in flights_list:\n",
    "        df_flight = pd.read_csv(os.path.join(flights_folder, flight))\n",
    "        touchdown_index = get_touchdown(df_flight)\n",
    "        df_analysis = df_flight[touchdown_index-n_observations:touchdown_index]\n",
    "        column_filter = df_flight.columns.values[df_flight.columns != 'Time']\n",
    "        flight_vector.append(\n",
    "                pd.melt(df_analysis.loc[:, column_filter])['value'].to_numpy()\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame({'flight_id': flights_list, 'flight_vector': flight_vector})\n",
    "\n",
    "\n",
    "def get_touchdown(df):\n",
    "    \"\"\"\n",
    "    Calculates instance of touchdown (landing).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    return df.iloc[df['Altitude'].idxmax():][df['Altitude'] <= 2].index[0]\n",
    "\n",
    "\n",
    "def plot_silhouette(sample_silhouette_values, n_clusters):\n",
    "    \"\"\"\n",
    "    Plots the silhouette of the clustering process.\n",
    "    \n",
    "    Ref:\n",
    "        https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_silhouette_values : numpy.ndarray\n",
    "        Silhouette coefficient for each sample.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : Figure\n",
    "        Matplotlib figure object.\n",
    "    ax : axis\n",
    "        Matplotlib axis object.\n",
    "\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[labels == i]\n",
    "    \n",
    "        ith_cluster_silhouette_values.sort()\n",
    "    \n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    \n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    \n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "    \n",
    "    ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "    \n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks(np.linspace(-1,1,11))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "source": [
    "## Inputs\n",
    "\n",
    "The first step in the analysis is to import the flight data and preprocess it. The preprocessing steps consist on selecting only a portion of a given flight, which is done by subsetting n_observations before the touchdown. The dataframe is then melted as described by the function **prepare_data** so the flight vector is obtained."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = os.path.dirname(\n",
    "    os.path.abspath(\n",
    "        inspect.getfile(\n",
    "            inspect.currentframe()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "flights_folder = os.path.join(os.path.dirname(os.path.dirname(currentdir)), 'input_flights')\n",
    "df_flights = prepare_data(flights_folder, n_observations=600)\n",
    "df_flights['flight_id_reduced'] = ['flight_'+str(i) for i in range(len(df_flights))] # reduced id add for plotting the dendrogram\n",
    "\n",
    "print(df_flights.head())"
   ]
  },
  {
   "source": [
    "## Preparing data for clustering\n",
    "\n",
    "Next the data is prepared to be compatible with the sci-kit learn library. The dataframe *flight_vector* column is converted to a numpy array in which each row is a flight and each column is a feature - in this case, a flight data parameter in a given instant.\n",
    "\n",
    "Afterwards the StandardScaler transformer standardizes the data by centering it (subtraction of the mean) and scaling it to unit variance (more info: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "A further necessary step is dimension reduction although it is not explored in this analysis which focuses only on the silhouette coefficients."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty([len(df_flights.flight_vector.to_numpy()), 9000])\n",
    "i = 0\n",
    "for nparray in df_flights.flight_vector.to_numpy():\n",
    "    X[i, :] = nparray\n",
    "    i += 1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "source": [
    "## Clustering\n",
    "\n",
    "Scipy's linkage function was used to perform agglomerative clustering (https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html).\n",
    "\n",
    "The output linkage matrix is then used as an input for the dendrogram function, which displays the clustering results on a plot. Finally the silhouette is calculated with sklearn's silhouette_score and silhouette_sample.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergings=linkage(X, method='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "dendrogram(mergings,\n",
    "           labels=df_flights['flight_id_reduced'].to_list(),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=12)\n",
    "fig.set_size_inches(24, 10)\n",
    "plt.yticks(range(0,250,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fcluster(mergings, 150, criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating flights df with cluster labels\n",
    "df_flights['cluster'] = labels\n",
    "try:\n",
    "    silhouette_avg = silhouette_score(X, labels)\n",
    "    sample_silhouette_values = silhouette_samples(X, labels)\n",
    "except:\n",
    "    silhouette_avg = np.nan\n",
    "    sample_silhouette_values = []\n",
    "\n",
    "if silhouette_avg is not np.nan:\n",
    "    df_flights['silhouette'] = sample_silhouette_values\n",
    "    print('Average silhouette: {}'.format(round(silhouette_avg, 3)))\n",
    "    plot_silhouette(sample_silhouette_values, len(list(set(labels))))"
   ]
  },
  {
   "source": [
    "## Conclusions\n",
    "\n",
    "Albeit interesting, quick and visually effective, the hierarchical clustering didn't provide good results at first, as shown by the silhouette plots. However an attempt at better results should be investigated within a complete process - inclusive of a dimension reduction step, e.g. - with a superior flight data source."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}